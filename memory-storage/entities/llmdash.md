# LLMDash
- relationship: Main Project
- type: Multi-Model AI Chat Platform
- description: Enterprise-grade AI chat platform based on LibreChat with advanced memory integration
- version: 2.0.0
- status: Production
- url: https://www.llmdash.com

## Technologies
- **Backend**: Node.js, Express.js, MongoDB
- **Frontend**: React, Vite, Tailwind CSS, Recoil
- **Process Management**: PM2 (cluster mode)
- **Reverse Proxy**: Nginx
- **Authentication**: JWT-based with refresh tokens
- **File Storage**: Local filesystem with OCR support
- **Memory System**: mem-agent-mcp with vLLM backend

## Architecture
### Services
1. **LibreChat Backend** (Port 3080)
   - Main API server
   - Handles chat conversations
   - Integrates with multiple LLM providers
   - Memory context injection via OrgMemory service

2. **LibreChat Frontend** (Port 3090/3092)
   - React-based UI
   - Real-time chat interface
   - File upload with OCR support
   - Responsive design

3. **Admin Dashboard Backend** (Port 5001)
   - Administrative API
   - User management
   - Model registry and pricing
   - Usage statistics

4. **Admin Dashboard Frontend** (Port 3091)
   - Admin UI built with React
   - Real-time monitoring
   - Cost usage tracking
   - Organization management

5. **API Relay Server** (Port 4000)
   - OpenAI-compatible API endpoint
   - Cursor IDE integration
   - API key management
   - Request routing to LibreChat

6. **Memory System (mem-agent-mcp)** (Port 8001)
   - vLLM-based memory service
   - Obsidian-style markdown storage
   - Context retrieval for conversations
   - Direct file reading for accuracy

## Features
### Core Features
- **Multiple LLM Support**: OpenAI (GPT-4, GPT-5), Claude, Gemini, Mistral
- **Conversation Management**: Save, search, export conversations
- **File Processing**: Upload and process PDFs, images with OCR
- **Memory Integration**: Automatic context injection from organizational memory
- **Admin Controls**: User management, model configuration, usage tracking

### Advanced Features
- **Model Registry**: Dynamic model configuration and pricing
- **Cost Tracking**: Per-user and per-model usage monitoring
- **Team Collaboration**: Shared conversations and memory
- **API Compatibility**: OpenAI-compatible API for external tools
- **Real-time Updates**: WebSocket support for streaming responses

## Deployment
### URLs
- **Main Application**: https://www.llmdash.com/chat
- **Admin Dashboard**: https://www.llmdash.com/admin
- **API Endpoint**: https://www.llmdash.com/v1

### Infrastructure
- **Server**: Ubuntu Linux with Nginx
- **Database**: MongoDB (local instance)
- **GPU**: RTX 5090 for vLLM inference
- **SSL**: Let's Encrypt certificates

## Configuration Files
- **LibreChat Config**: `librechat.yaml`
- **Environment**: `.env` files for each service
- **PM2 Config**: `ecosystem.config.js`
- **Nginx Config**: `/etc/nginx/sites-available/llmdash`

## Recent Updates
- 2025-09-18: Improved memory system with direct file reading
- 2025-09-17: Integrated mem-agent-mcp for organizational memory
- 2025-09-10: Added model registry and pricing management
- 2025-09-09: Implemented admin dashboard with cost tracking

## Development
### Commands
- **Start all services**: `pm2 start ecosystem.config.js`
- **Build frontend**: `npm run build:client`
- **Development mode**: `npm run backend:dev` + `npm run frontend:dev`
- **View logs**: `pm2 logs [service-name]`

## Integration Points
- **Cursor IDE**: Via API relay server at /v1 endpoint
- **Memory System**: Automatic context injection in conversations
- **Admin API**: REST endpoints for management operations
- **File Processing**: OCR.space API integration

## Security
- JWT authentication with refresh tokens
- Rate limiting on API endpoints
- Path traversal protection
- MongoDB injection prevention
- CORS configuration for production domains

## Performance
- PM2 cluster mode with 4 workers
- Response caching for static content
- Optimized MongoDB queries with indexes
- Lazy loading for frontend components
- GPU acceleration for memory inference

## Update 2025-09-18 19:10
ëŸ°ì¹­ ì˜ˆì •ì¼: 2025ë…„ 12ì›” 31ì¼ (MCP íˆ´ì„ í†µí•´ ì—…ë°ì´íŠ¸ë¨)

## Update 2025-09-17
ë² íƒ€ í…ŒìŠ¤íŠ¸ ì°¸ê°€ì 100ëª… ëª¨ì§‘ ì¤‘

## Update 2025-09-17
ìƒˆë¡œìš´ Claude 3.5 Sonnet ëª¨ë¸ ì¶”ê°€

## Update 2025-09-17
ì›”ê°„ í™œì„± ì‚¬ìš©ì 1,000ëª… ëŒíŒŒ

## Update 2025-09-17
ì²« ë²ˆì§¸ ìœ ë£Œ ê³ ê° íšë“ (Enterprise Plan)


## Update: 2025-09-18 09:40:22

### MCP Integration Test Results (2025-09-18 09:40:22)

**Test Summary:**
- MCP interface successfully connected
- Memory read operations verified
- Memory write operations functional
- File modification via add_memory tool confirmed

**Technical Details:**
- MCP Protocol: stdio-based communication
- Backend: vLLM server on port 8001
- Memory Storage: Markdown files in /home/jonghooy/work/llmdash-claude/memory-storage
- Entity Update Method: Append mode with timestamp

**Test Status:** âœ… PASSED

*** 2015.9.13. Check Manual Update is Valid. **


## Update: 2025-09-18 12:22:22

## Direct MCP Test - 2025-09-18T03:22:22.129Z

**Launch Date**: December 3rd, 2024 (Updated via Direct MCP Client)

### MCP Protocol Status
- Direct Python execution: âœ… WORKING
- MCP tools integration: âœ… SUCCESS
- Memory persistence: âœ… VERIFIED

Updated at: 2025-09-18T03:22:22.129Z

## Update 2025-09-18 19:15
### ìµœê·¼ ê°œë°œ ì§„í–‰ì‚¬í•­

**MCP ì„œë²„ ì ‘ê·¼ ì•Œë¦¼ ê¸°ëŠ¥ ì¶”ê°€**
- MCP ì„œë²„ ì ‘ì† ì‹œ ì‚¬ìš©ìì—ê²Œ ì‹¤ì‹œê°„ ì•Œë¦¼ í‘œì‹œ
- SSE(Server-Sent Events)ë¥¼ í†µí•œ ìƒíƒœ ë©”ì‹œì§€ ì „ì†¡
- ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸ ê³¼ì •ì˜ íˆ¬ëª…ì„± í™•ë³´

**ì•Œë¦¼ ë©”ì‹œì§€ ì¢…ë¥˜**:
- ğŸ”„ [MCP ì„œë²„ ì ‘ì† ì¤‘] - ì„œë¹„ìŠ¤ ì—°ê²° ì‹œì‘
- âœ… MCP ì„œë²„ ì—°ê²° ì„±ê³µ
- ğŸ“ ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸ ì§„í–‰ ì¤‘
- âœ… ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸ ì™„ë£Œ
- âŒ ì˜¤ë¥˜ ë°œìƒ ì‹œ ìƒì„¸ ë©”ì‹œì§€

**ê¸°ìˆ  êµ¬í˜„**:
- MemoryUpdateToolì— sendEvent í†µí•©
- handleTools.jsì—ì„œ response ê°ì²´ ì „ë‹¬
- ì‹¤ì‹œê°„ ì‚¬ìš©ì í”¼ë“œë°± ì œê³µ


## Update: 2025-09-18 21:13:36
- ì¸í¼ëŸ°ìŠ¤ ì†ë„: ì§ˆì˜ë‹¹ ì•½ 0.25ì´ˆ (ì†ë„ ìµœì í™”ë¨, ê¸°ì¡´ 0.35ì´ˆì—ì„œ ê°œì„ )

## Update 2025-09-18
í•´ì¤˜

## Update 2025-09-18
í•´ì¤˜

## Update 2025-09-18
í•´ì¤˜
