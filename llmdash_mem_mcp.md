# LLMDash + mem-agent-mcp í†µí•© ê°€ì´ë“œ

## ðŸŽ¯ í”„ë¡œì íŠ¸ ê°œìš”

LLMDashì™€ mem-agent-mcpë¥¼ RTX 5090 GPUì—ì„œ í†µí•©í•˜ì—¬ ê°œì¸ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œì„ êµ¬ì¶•í•œ í”„ë¡œì íŠ¸ìž…ë‹ˆë‹¤.

### ì£¼ìš” ì„±ê³¼
- âœ… **RTX 5090 GPU ì§€ì›**: PyTorch 2.7.1+cu128ë¡œ í•´ê²°
- âœ… **vLLM í†µí•©**: OpenAI í˜¸í™˜ APIë¡œ ê³ ì† ì¶”ë¡ 
- âœ… **MCP í”„ë¡œí† ì½œ**: stdio ê¸°ë°˜ ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ ì¸í„°íŽ˜ì´ìŠ¤
- âœ… **ë©”ëª¨ë¦¬ ê´€ë¦¬**: ì½ê¸°/ì“°ê¸°/ê²€ìƒ‰ ê¸°ëŠ¥ ì™„ë²½ êµ¬í˜„

## ðŸ“‹ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

- **GPU**: NVIDIA RTX 5090 (sm_120, CUDA 12.8+)
- **Python**: 3.11+
- **PyTorch**: 2.7.1+cu128 (RTX 5090 ì§€ì›)
- **vLLM**: 0.10.0
- **ë©”ëª¨ë¦¬**: 32GB+ RAM, 32GB+ GPU ë©”ëª¨ë¦¬

## ðŸš€ ì„¤ì¹˜ ë°©ë²•

### 1. í”„ë¡œì íŠ¸ í´ë¡  ë° í™˜ê²½ ì„¤ì •

```bash
# í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬
cd /home/jonghooy/work/llmdash-claude

# mem-agent-mcp í´ë¡ 
git clone https://github.com/skydeckai/mem-agent-mcp
cd mem-agent-mcp

# Python ê°€ìƒí™˜ê²½ ìƒì„±
python3 -m venv .venv
source .venv/bin/activate

# uv ì„¤ì¹˜ (ë¹ ë¥¸ íŒ¨í‚¤ì§€ ê´€ë¦¬)
curl -LsSf https://astral.sh/uv/install.sh | sh
export PATH="$HOME/.local/bin:$PATH"
```

### 2. PyTorch 2.7.1+cu128 ì„¤ì¹˜ (RTX 5090 ì§€ì›)

```bash
# RTX 5090ì„ ì§€ì›í•˜ëŠ” PyTorch ì„¤ì¹˜
~/.local/bin/uv pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cu128

# vLLM ì„¤ì¹˜
~/.local/bin/uv pip install vllm

# ê¸°íƒ€ ì˜ì¡´ì„±
~/.local/bin/uv pip install fastmcp transformers accelerate
```

### 3. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

```bash
# Hugging Face CLI ì„¤ì¹˜
pip install huggingface-hub

# mem-agent ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì•½ 7.6GB)
huggingface-cli download skydeckai/mem-agent \
    --local-dir ./models/mem-agent \
    --local-dir-use-symlinks False
```

### 4. ë©”ëª¨ë¦¬ ìŠ¤í† ë¦¬ì§€ ì´ˆê¸°í™”

```bash
# ë©”ëª¨ë¦¬ ë””ë ‰í† ë¦¬ ìƒì„±
mkdir -p /home/jonghooy/work/llmdash-claude/memory-storage/entities

# ì‚¬ìš©ìž ì •ë³´ ìƒì„±
cat > /home/jonghooy/work/llmdash-claude/memory-storage/user.md << 'EOF'
# User Information
- user_name: Your Name
- birth_date: YYYY-MM-DD
- location: Your Location

## User Relationships
- company: [[entities/your-company.md]]
- project: [[entities/your-project.md]]
EOF
```

## ðŸ”§ ì‹¤í–‰ ë°©ë²•

### 1. vLLM ì„œë²„ ì‹¤í–‰ (GPU ì¶”ë¡ )

```bash
cd /home/jonghooy/work/llmdash-claude/mem-agent-mcp
source .venv/bin/activate

# vLLM ì„œë²„ ì‹œìž‘ (í¬íŠ¸ 8001)
VLLM_WORKER_MULTIPROC_METHOD=spawn python -m vllm.entrypoints.openai.api_server \
    --model ./models/mem-agent \
    --trust-remote-code \
    --dtype bfloat16 \
    --max-model-len 2048 \
    --gpu-memory-utilization 0.8 \
    --port 8001
```

### 2. MCP ì„œë²„ ì‹¤í–‰ (ë©”ëª¨ë¦¬ ì¸í„°íŽ˜ì´ìŠ¤)

```bash
# ìƒˆ í„°ë¯¸ë„ì—ì„œ
cd /home/jonghooy/work/llmdash-claude/mem-agent-mcp
source .venv/bin/activate

# MCP ì„œë²„ ì‹œìž‘ (vLLM ë°±ì—”ë“œ ì‚¬ìš©)
python mcp_client_vllm.py
```

## ðŸ“¡ API ì‚¬ìš©ë²•

### vLLM API (OpenAI í˜¸í™˜)

```python
import requests

# í…ìŠ¤íŠ¸ ìƒì„±
response = requests.post(
    "http://localhost:8001/v1/completions",
    json={
        "model": "./models/mem-agent",
        "prompt": "What is LLMDash?",
        "max_tokens": 100,
        "temperature": 0.7
    }
)

print(response.json()['choices'][0]['text'])
```

### MCP í”„ë¡œí† ì½œ (ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ)

```python
import asyncio
from mcp import ClientSession, StdioServerParameters
from mcp.client.stdio import stdio_client

async def use_mcp():
    # MCP ì„œë²„ ì—°ê²°
    server_params = StdioServerParameters(
        command="python",
        args=["mcp_client_vllm.py"]
    )

    async with stdio_client(server_params) as (read, write):
        async with ClientSession(read, write) as session:
            await session.initialize()

            # 1. ë©”ëª¨ë¦¬ ì¡°íšŒ
            result = await session.call_tool(
                "query_with_memory",
                {"question": "Tell me about myself"}
            )

            # 2. ë©”ëª¨ë¦¬ ê²€ìƒ‰
            result = await session.call_tool(
                "search_memory",
                {"query": "project"}
            )

            # 3. ë©”ëª¨ë¦¬ ì¶”ê°€
            result = await session.call_tool(
                "add_memory",
                {
                    "entity_name": "new-topic",
                    "content": "New information to remember"
                }
            )

            # 4. ì‚¬ìš©ìž ì •ë³´ ì—…ë°ì´íŠ¸
            result = await session.call_tool(
                "update_user_memory",
                {
                    "key": "favorite_hobby",
                    "value": "Programming"
                }
            )

            # 5. ë©”ëª¨ë¦¬ ëª©ë¡ ì¡°íšŒ
            result = await session.call_tool("list_memories", {})

asyncio.run(use_mcp())
```

## ðŸ› ï¸ MCP ë„êµ¬ ëª©ë¡

| ë„êµ¬ëª… | ì„¤ëª… | íŒŒë¼ë¯¸í„° |
|--------|------|----------|
| `query_with_memory` | ë©”ëª¨ë¦¬ ì»¨í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ ì§ˆì˜ | `question: str` |
| `search_memory` | ë©”ëª¨ë¦¬ì—ì„œ íŠ¹ì • ì •ë³´ ê²€ìƒ‰ | `query: str` |
| `list_memories` | ëª¨ë“  ë©”ëª¨ë¦¬ íŒŒì¼ ëª©ë¡ ì¡°íšŒ | ì—†ìŒ |
| `add_memory` | ìƒˆ ë©”ëª¨ë¦¬ ì—”í‹°í‹° ì¶”ê°€ | `entity_name: str`, `content: str` |
| `update_user_memory` | ì‚¬ìš©ìž ì •ë³´ ì—…ë°ì´íŠ¸ | `key: str`, `value: str` |
| `get_vllm_status` | vLLM ì„œë²„ ìƒíƒœ í™•ì¸ | ì—†ìŒ |

## ðŸ“‚ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
/home/jonghooy/work/llmdash-claude/
â”œâ”€â”€ mem-agent-mcp/
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ mem-agent/           # Qwen3 ê¸°ë°˜ 7.6GB ëª¨ë¸
â”‚   â”œâ”€â”€ mcp_client_vllm.py       # MCP ì„œë²„ (vLLM ë°±ì—”ë“œ)
â”‚   â”œâ”€â”€ mcp_server_gpu.py        # GPU ì§ì ‘ ì‚¬ìš© ë²„ì „
â”‚   â”œâ”€â”€ test-vllm-api.py         # vLLM API í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ test-mcp-vllm.py         # MCP í†µí•© í…ŒìŠ¤íŠ¸
â”‚   â””â”€â”€ test-memory-operations.py # ë©”ëª¨ë¦¬ ìž‘ì—… í…ŒìŠ¤íŠ¸
â”œâ”€â”€ memory-storage/
â”‚   â”œâ”€â”€ user.md                  # ì‚¬ìš©ìž ì •ë³´
â”‚   â””â”€â”€ entities/                # ì—”í‹°í‹°ë³„ ë©”ëª¨ë¦¬
â”‚       â”œâ”€â”€ llmdash.md
â”‚       â”œâ”€â”€ mem-agent-mcp.md
â”‚       â””â”€â”€ vLLM-integration.md
â””â”€â”€ LibreChat/                   # LLMDash ë©”ì¸ ì• í”Œë¦¬ì¼€ì´ì…˜
```

## ðŸ” í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

### vLLM API í…ŒìŠ¤íŠ¸
```bash
python test-vllm-api.py
```

### MCP í†µí•© í…ŒìŠ¤íŠ¸
```bash
python test-mcp-vllm.py
```

### ë©”ëª¨ë¦¬ ìž‘ì—… í…ŒìŠ¤íŠ¸
```bash
python test-memory-operations.py
```

## ðŸ“Š ì„±ëŠ¥ ì§€í‘œ

- **ëª¨ë¸ í¬ê¸°**: 7.6GB (Qwen3 ì•„í‚¤í…ì²˜)
- **GPU ë©”ëª¨ë¦¬ ì‚¬ìš©**:
  - ëª¨ë¸ ë¡œë“œ: ~7.5GB
  - ì‹¤í–‰ ì‹œ: ~27GB (KV ìºì‹œ í¬í•¨)
- **ì¶”ë¡  ì†ë„**: ~0.35ì´ˆ/ì¿¼ë¦¬
- **ìµœëŒ€ ì»¨í…ìŠ¤íŠ¸**: 2,048 í† í° (ì„¤ì • ê°€ëŠ¥)
- **GPU í™œìš©ë¥ **: 80-92%

## ðŸ› íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### RTX 5090 í˜¸í™˜ì„± ë¬¸ì œ
```bash
# PyTorch 2.7.1+cu128 ìž¬ì„¤ì¹˜
~/.local/bin/uv pip install torch==2.7.1 --index-url https://download.pytorch.org/whl/cu128 --force-reinstall
```

### vLLM í¬íŠ¸ ì¶©ëŒ
```bash
# ì‚¬ìš© ì¤‘ì¸ í¬íŠ¸ í™•ì¸
lsof -i :8001

# ë‹¤ë¥¸ í¬íŠ¸ë¡œ ì‹¤í–‰
--port 8002
```

### ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°ì •
--gpu-memory-utilization 0.5  # 50%ë§Œ ì‚¬ìš©
```

## ðŸ”— ê´€ë ¨ ë§í¬

- [mem-agent-mcp GitHub](https://github.com/skydeckai/mem-agent-mcp)
- [vLLM Documentation](https://docs.vllm.ai/)
- [MCP Protocol Spec](https://github.com/anthropics/mcp)
- [LibreChat/LLMDash](https://github.com/danny-avila/LibreChat)

## ðŸ“ ì£¼ìš” ì—…ë°ì´íŠ¸ ë‚´ì—­

- **2025-09-18**: RTX 5090 ì§€ì› ì™„ë£Œ (PyTorch 2.7.1+cu128)
- **2025-09-18**: vLLM í†µí•© ì„±ê³µ
- **2025-09-18**: MCP ë©”ëª¨ë¦¬ ì¶”ê°€/ì—…ë°ì´íŠ¸ ê¸°ëŠ¥ êµ¬í˜„
- **2025-09-18**: ì „ì²´ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ

## âœ¨ íŠ¹ì§•

1. **GPU ê°€ì†**: RTX 5090ì˜ ê°•ë ¥í•œ ì„±ëŠ¥ í™œìš©
2. **ë©”ëª¨ë¦¬ ì‹œìŠ¤í…œ**: Obsidian ìŠ¤íƒ€ì¼ ë§ˆí¬ë‹¤ìš´ ê¸°ë°˜
3. **OpenAI í˜¸í™˜**: ê¸°ì¡´ ì• í”Œë¦¬ì¼€ì´ì…˜ê³¼ ì‰½ê²Œ í†µí•©
4. **MCP í”„ë¡œí† ì½œ**: í‘œì¤€í™”ëœ AI ë„êµ¬ ì¸í„°íŽ˜ì´ìŠ¤
5. **í™•ìž¥ ê°€ëŠ¥**: ìƒˆë¡œìš´ ë©”ëª¨ë¦¬ íƒ€ìž…ê³¼ ë„êµ¬ ì¶”ê°€ ìš©ì´

---

*ì´ ë¬¸ì„œëŠ” LLMDashì™€ mem-agent-mcp í†µí•© í”„ë¡œì íŠ¸ì˜ ê³µì‹ ê°€ì´ë“œìž…ë‹ˆë‹¤.*