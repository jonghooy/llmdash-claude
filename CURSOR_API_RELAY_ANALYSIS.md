# Cursor IDEì™€ API Relay Server í†µí•© ë¶„ì„

## 1. Cursorì˜ LLM API ì‚¬ìš© ë°©ì‹ ë¶„ì„

### 1.1 Cursorì˜ í˜„ì¬ ë™ì‘ ë°©ì‹
```
Cursor IDE â†’ OpenAI/Anthropic API (ì§ì ‘ ì—°ê²°)
           â†“
    ì‚¬ìš©ì ê°œì¸ API í‚¤ ì‚¬ìš©
```

### 1.2 Cursorì˜ API ì„¤ì • ë°©ì‹
- **Settings â†’ Models**: API í‚¤ ì…ë ¥
- **Supported Providers**: 
  - OpenAI (GPT-4, GPT-3.5)
  - Anthropic (Claude)
  - Azure OpenAI
  - Custom endpoints (ì¤‘ìš”!)

## 2. Relay Serverë¥¼ í†µí•œ í†µí•© ê°€ëŠ¥ì„±

### âœ… **ê°€ëŠ¥í•œ ì‹œë‚˜ë¦¬ì˜¤**

#### ë°©ë²• 1: Custom Endpoint í™œìš©
```javascript
// Cursor ì„¤ì •ì—ì„œ Custom Endpoint ì„¤ì •
{
  "openai": {
    "apiKey": "lc_prod_xxxxxxxxxx",  // Relay Server API Key
    "baseUrl": "https://your-relay-server.com/v1"  // Relay Server URL
  }
}
```

#### ë°©ë²• 2: Proxy ë°©ì‹
```
Cursor â†’ Relay Server (OpenAI í˜¸í™˜ API) â†’ ì‹¤ì œ LLM Provider
         â†“
    í†µê³„ ìˆ˜ì§‘ ë° ê´€ë¦¬
```

### ğŸ¯ **êµ¬í˜„ ì „ëµ**

#### 2.1 OpenAI í˜¸í™˜ API êµ¬í˜„
```javascript
// Relay Serverì—ì„œ OpenAI API ì™„ë²½ í˜¸í™˜ ì—”ë“œí¬ì¸íŠ¸ ì œê³µ
POST /v1/chat/completions     // Cursorê°€ ì‚¬ìš©í•˜ëŠ” ì£¼ìš” ì—”ë“œí¬ì¸íŠ¸
POST /v1/completions
POST /v1/embeddings
GET  /v1/models
```

#### 2.2 Cursor ì„¤ì • ë°©ë²•
```json
// Cursorì˜ settings.json
{
  "cursor.ai.providers": {
    "openai": {
      "enabled": true,
      "apiKey": "lc_team_dev_xxxxxxxxxxxx",
      "baseUrl": "http://localhost:4000/v1",  // Relay Server
      "models": ["gpt-4", "gpt-3.5-turbo"]
    },
    "anthropic": {
      "enabled": true,
      "apiKey": "lc_team_dev_yyyyyyyyyyyy",
      "baseUrl": "http://localhost:4000/anthropic/v1"
    }
  }
}
```

## 3. êµ¬ì²´ì ì¸ êµ¬í˜„ ë°©ì•ˆ

### 3.1 API Relay Server êµ¬ì¡°
```javascript
// 1. Request Interceptor
app.post('/v1/chat/completions', async (req, res) => {
  // API í‚¤ ê²€ì¦
  const apiKey = req.headers.authorization?.replace('Bearer ', '');
  const keyInfo = await validateApiKey(apiKey);
  
  // ì‚¬ìš©ì ë° íŒ€ ì‹ë³„
  const { userId, teamId, clientApp } = keyInfo;
  
  // Cursor íŠ¹ì • ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
  const metadata = {
    source: 'cursor',
    feature: req.headers['x-cursor-feature'],  // autocomplete, chat, etc.
    fileType: req.headers['x-cursor-file-type'],
    projectId: req.headers['x-cursor-project']
  };
  
  // ìš”ì²­ ê¸°ë¡
  await logApiRequest(apiKey, req.body, metadata);
  
  // ì‹¤ì œ LLM Providerë¡œ ì „ë‹¬
  const response = await forwardToProvider(req.body, keyInfo.provider);
  
  // ì‚¬ìš©ëŸ‰ ê¸°ë¡
  await trackUsage(apiKey, response.usage, metadata);
  
  // ì‘ë‹µ ë°˜í™˜
  res.json(response);
});
```

### 3.2 í†µê³„ ìˆ˜ì§‘ í•­ëª©
```javascript
{
  // Cursor íŠ¹í™” í†µê³„
  cursorMetrics: {
    // ê¸°ëŠ¥ë³„ ì‚¬ìš©ëŸ‰
    features: {
      autocomplete: { requests: 1234, tokens: 50000 },
      chat: { requests: 456, tokens: 30000 },
      edit: { requests: 789, tokens: 40000 },
      terminal: { requests: 123, tokens: 10000 }
    },
    
    // ì–¸ì–´ë³„ ì‚¬ìš©ëŸ‰
    languages: {
      javascript: { requests: 500, tokens: 25000 },
      python: { requests: 300, tokens: 15000 },
      typescript: { requests: 400, tokens: 20000 }
    },
    
    // ì‹œê°„ëŒ€ë³„ íŒ¨í„´
    hourlyUsage: [...],
    
    // í”„ë¡œì íŠ¸ë³„ í†µê³„
    projects: {
      'project-a': { requests: 200, tokens: 10000 },
      'project-b': { requests: 150, tokens: 8000 }
    },
    
    // ê°œë°œìë³„ í†µê³„
    developers: {
      'dev1@team.com': { requests: 300, tokens: 15000 },
      'dev2@team.com': { requests: 250, tokens: 12000 }
    }
  }
}
```

## 4. Admin Dashboard í†µí•©

### 4.1 Cursor ì „ìš© ëŒ€ì‹œë³´ë“œ
```
ğŸ“Š Cursor Usage Dashboard
â”œâ”€â”€ ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§
â”‚   â”œâ”€â”€ í˜„ì¬ í™œì„± ì„¸ì…˜
â”‚   â”œâ”€â”€ ë¶„ë‹¹ ìš”ì²­ ìˆ˜
â”‚   â””â”€â”€ ì‘ë‹µ ì‹œê°„
â”œâ”€â”€ ê¸°ëŠ¥ë³„ ë¶„ì„
â”‚   â”œâ”€â”€ Autocomplete ì‚¬ìš©ëŸ‰
â”‚   â”œâ”€â”€ Chat ì‚¬ìš©ëŸ‰
â”‚   â”œâ”€â”€ Code Edit ì‚¬ìš©ëŸ‰
â”‚   â””â”€â”€ Terminal Command ì‚¬ìš©ëŸ‰
â”œâ”€â”€ ê°œë°œìë³„ í†µê³„
â”‚   â”œâ”€â”€ ê°œì¸ë³„ ì‚¬ìš©ëŸ‰
â”‚   â”œâ”€â”€ ìƒì‚°ì„± ì§€í‘œ
â”‚   â””â”€â”€ ë¹„ìš© í• ë‹¹
â””â”€â”€ ë¹„ìš© ë¶„ì„
    â”œâ”€â”€ ì¼ë³„/ì›”ë³„ ë¹„ìš©
    â”œâ”€â”€ ëª¨ë¸ë³„ ë¹„ìš©
    â””â”€â”€ ì˜ˆìƒ ì²­êµ¬ì•¡
```

### 4.2 íŒ€ ê´€ë¦¬ ê¸°ëŠ¥
```javascript
// íŒ€ë³„ API í‚¤ ê´€ë¦¬
{
  teamId: "team-123",
  name: "Development Team",
  apiKeys: [
    {
      key: "lc_team_dev_xxx",
      name: "Cursor Development",
      limits: {
        dailyTokens: 1000000,
        monthlyBudget: 500
      },
      members: ["dev1@team.com", "dev2@team.com"]
    }
  ]
}
```

## 5. ì‹¤ì œ êµ¬í˜„ ì˜ˆì‹œ

### 5.1 Relay Server ì„¤ì •
```typescript
// relay-server/src/providers/cursor.ts
export class CursorProvider {
  async handleRequest(req: Request): Promise<Response> {
    // 1. Cursor íŠ¹í™” í—¤ë” íŒŒì‹±
    const cursorContext = {
      feature: req.headers['x-cursor-feature'],
      file: req.headers['x-cursor-current-file'],
      language: req.headers['x-cursor-language'],
      projectPath: req.headers['x-cursor-project-path']
    };
    
    // 2. ìŠ¤ë§ˆíŠ¸ ë¼ìš°íŒ… (ê¸°ëŠ¥ë³„ ëª¨ë¸ ì„ íƒ)
    const model = this.selectOptimalModel(cursorContext);
    
    // 3. ì»¨í…ìŠ¤íŠ¸ ìµœì í™”
    const optimizedRequest = this.optimizeForCursor(req.body, cursorContext);
    
    // 4. ìºì‹± ì²´í¬ (ë°˜ë³µì ì¸ ìë™ì™„ì„± ìš”ì²­)
    if (cursorContext.feature === 'autocomplete') {
      const cached = await this.checkCache(optimizedRequest);
      if (cached) return cached;
    }
    
    // 5. ì‹¤ì œ ìš”ì²­ ì²˜ë¦¬
    return this.processRequest(optimizedRequest, model);
  }
  
  selectOptimalModel(context: CursorContext): string {
    // ê¸°ëŠ¥ë³„ ìµœì  ëª¨ë¸ ì„ íƒ
    switch(context.feature) {
      case 'autocomplete':
        return 'gpt-3.5-turbo';  // ë¹ ë¥¸ ì‘ë‹µ
      case 'chat':
        return 'gpt-4';  // ë†’ì€ í’ˆì§ˆ
      case 'edit':
        return 'claude-3-sonnet';  // ì½”ë“œ í¸ì§‘ íŠ¹í™”
      default:
        return 'gpt-3.5-turbo';
    }
  }
}
```

### 5.2 ì‚¬ìš©ëŸ‰ ì¶”ì 
```typescript
// ìƒì„¸ ì‚¬ìš©ëŸ‰ ì¶”ì 
async function trackCursorUsage(
  apiKey: string,
  usage: Usage,
  context: CursorContext
) {
  await db.collection('cursor_usage').insertOne({
    apiKey,
    timestamp: new Date(),
    
    // Cursor íŠ¹í™” ì •ë³´
    cursor: {
      feature: context.feature,
      file: context.file,
      language: context.language,
      project: context.projectPath
    },
    
    // ì‚¬ìš©ëŸ‰
    usage: {
      promptTokens: usage.prompt_tokens,
      completionTokens: usage.completion_tokens,
      totalTokens: usage.total_tokens,
      estimatedCost: calculateCost(usage, model)
    },
    
    // ì„±ëŠ¥ ì§€í‘œ
    performance: {
      latency: responseTime,
      cached: wasCache,
      modelUsed: model
    }
  });
  
  // ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­ ì—…ë°ì´íŠ¸
  await updateRealtimeMetrics(apiKey, usage);
  
  // í•œë„ ì²´í¬
  await checkLimits(apiKey, usage);
}
```

## 6. ì¥ì  ë° ì´ì 

### 6.1 íŒ€/ì¡°ì§ ê´€ì 
- âœ… **ë¹„ìš© í†µì œ**: íŒ€ ì „ì²´ API ì‚¬ìš©ëŸ‰ ì¤‘ì•™ ê´€ë¦¬
- âœ… **ì˜ˆì‚° ê´€ë¦¬**: ë¶€ì„œë³„/í”„ë¡œì íŠ¸ë³„ ë¹„ìš© í• ë‹¹
- âœ… **ë³´ì•ˆ**: ê°œì¸ API í‚¤ ë…¸ì¶œ ë°©ì§€
- âœ… **í†µê³„**: ê°œë°œìë³„ ìƒì‚°ì„± ì§€í‘œ

### 6.2 ê°œë°œì ê´€ì 
- âœ… **ê°„í¸í•œ ì„¤ì •**: í•˜ë‚˜ì˜ API í‚¤ë¡œ ëª¨ë“  ëª¨ë¸ ì‚¬ìš©
- âœ… **ìë™ ìµœì í™”**: ì‘ì—…ë³„ ìµœì  ëª¨ë¸ ìë™ ì„ íƒ
- âœ… **ìºì‹±**: ë°˜ë³µ ìš”ì²­ ìºì‹±ìœ¼ë¡œ ì†ë„ í–¥ìƒ
- âœ… **ì‚¬ìš©ëŸ‰ í™•ì¸**: ê°œì¸ ì‚¬ìš©ëŸ‰ ëŒ€ì‹œë³´ë“œ

### 6.3 ê´€ë¦¬ì ê´€ì 
- âœ… **í†µí•© ê´€ë¦¬**: ëª¨ë“  AI ë„êµ¬ ì‚¬ìš©ëŸ‰ í•œê³³ì—ì„œ ê´€ë¦¬
- âœ… **ë¹„ìš© ìµœì í™”**: ì‚¬ìš© íŒ¨í„´ ë¶„ì„ í›„ ìµœì í™”
- âœ… **ì»´í”Œë¼ì´ì–¸ìŠ¤**: ë°ì´í„° ë³´ì•ˆ ë° ê°ì‚¬ ë¡œê·¸
- âœ… **ìë™í™”**: í•œë„ ì´ˆê³¼ì‹œ ìë™ ì•Œë¦¼/ì°¨ë‹¨

## 7. êµ¬í˜„ ë¡œë“œë§µ

### Phase 1: ê¸°ë³¸ Proxy (1ì£¼)
- [ ] OpenAI í˜¸í™˜ API êµ¬í˜„
- [ ] ê¸°ë³¸ ì¸ì¦ ë° ë¼ìš°íŒ…
- [ ] ì‚¬ìš©ëŸ‰ ë¡œê¹…

### Phase 2: Cursor íŠ¹í™” ê¸°ëŠ¥ (1ì£¼)
- [ ] Cursor ë©”íƒ€ë°ì´í„° íŒŒì‹±
- [ ] ê¸°ëŠ¥ë³„ ëª¨ë¸ ë¼ìš°íŒ…
- [ ] ìë™ì™„ì„± ìºì‹±

### Phase 3: í†µê³„ ë° ë¶„ì„ (1ì£¼)
- [ ] Cursor ì‚¬ìš© íŒ¨í„´ ë¶„ì„
- [ ] ê°œë°œìë³„ í†µê³„
- [ ] ë¹„ìš© ë¦¬í¬íŠ¸

### Phase 4: ìµœì í™” (1ì£¼)
- [ ] ìŠ¤ë§ˆíŠ¸ ìºì‹±
- [ ] ìš”ì²­ ë°°ì¹­
- [ ] ëª¨ë¸ ìµœì í™”

## 8. ì˜ˆìƒ ë¬¸ì œ ë° í•´ê²°ë°©ì•ˆ

### 8.1 ë¬¸ì œì 
1. **ë ˆì´í„´ì‹œ ì¦ê°€**: Relay Server ê²½ìœ ë¡œ ì¸í•œ ì§€ì—°
2. **ìŠ¤íŠ¸ë¦¬ë°**: Cursorì˜ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ì²˜ë¦¬
3. **í˜¸í™˜ì„±**: Cursor ì—…ë°ì´íŠ¸ì‹œ API ë³€ê²½

### 8.2 í•´ê²°ë°©ì•ˆ
1. **ì—£ì§€ ë°°í¬**: ê°€ê¹Œìš´ ì§€ì—­ì— Relay Server ë°°í¬
2. **SSE/WebSocket**: ìŠ¤íŠ¸ë¦¬ë° ì™„ë²½ ì§€ì›
3. **ë²„ì „ ê´€ë¦¬**: API ë²„ì „ë³„ í˜¸í™˜ì„± ìœ ì§€

## 9. ê²°ë¡ 

### âœ… **ê°€ëŠ¥ ì—¬ë¶€: ì™„ì „íˆ ê°€ëŠ¥**

Cursorì˜ Custom Endpoint ê¸°ëŠ¥ì„ í™œìš©í•˜ë©´ Relay Serverë¥¼ í†µí•œ ì™„ë²½í•œ í†µí•©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

### ğŸ“Š **ì˜ˆìƒ íš¨ê³¼**
- íŒ€ ì „ì²´ API ë¹„ìš© 30-50% ì ˆê° (ìµœì í™” ë° ìºì‹±)
- ê°œë°œì ìƒì‚°ì„± ì§€í‘œ í™•ë³´
- ë³´ì•ˆ ë° ì»´í”Œë¼ì´ì–¸ìŠ¤ ê°•í™”
- ì¤‘ì•™ ì§‘ì¤‘ì‹ AI ë„êµ¬ ê´€ë¦¬

### ğŸš€ **ì¦‰ì‹œ ì‹œì‘ ê°€ëŠ¥í•œ ì‘ì—…**
1. OpenAI í˜¸í™˜ Relay Server MVP êµ¬ì¶•
2. Cursorì—ì„œ Custom Endpoint í…ŒìŠ¤íŠ¸
3. ê¸°ë³¸ ì‚¬ìš©ëŸ‰ ì¶”ì  êµ¬í˜„
4. Admin Dashboard í†µí•©

êµ¬í˜„ì„ ì‹œì‘í•˜ì‹œê² ìŠµë‹ˆê¹Œ?